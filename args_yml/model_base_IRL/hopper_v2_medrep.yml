# halfcheetah experiments debug
#N Î» h: 12 39.08 43
args:
    env_name: hopper-medium-replay-v2 # d4rl mixed, supposedly the best for MOPO
    reward_head: True
    logvar_head: True
    states: 'uniform'
    steps_k: 43
    reward_steps: 200
    num_rollouts_per_step: 50
    policy_update_steps: 1000
    train_policy_every: 100
    train_val_ratio: 0.2
    real_sample_ratio: 0.05
    model_train_freq: 1000
    max_timesteps: 10000000
    n_eval_rollouts: 10
    num_models: 7
    num_elites: 5
    d4rl: True
    model_retain_epochs: 5
    mopo: True
    mopo_lam: 5.90
    offline_epochs: 1000
    save_model: True
    save_policy: True
    load_model_dir: /world_model/model_hopper/hopper-v2-medreplay/checkpoints/model_saved_weights/Model_hopper-medium-replay-v2_seed0_2023_01_05_03-33-00/
    train_memory: 2000000
    val_memory: 500000